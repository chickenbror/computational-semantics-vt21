{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A2: Vector Semantics\n",
    "\n",
    "Nikolai Ilinykh, Mehdi Ghanimifard, Wafia Adouane and Simon Dobnik\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read [the following instructions](https://github.com/sdobnik/computational-semantics/blob/master/README.md) on how to work on group assignments.\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below.\n",
    "\n",
    "In this lab we will look at how to build distributional semantic models from corpora and use semantic similarity captured by these models to do semantic tasks. We are also going to examine how different vector composition functions for phrases affect both the model and the learned information about similarities.  \n",
    "\n",
    "Note that this lab uses a code from `dist_erk.py`, which contains functions that highly resemble those shown during the lecture. In the end, you can use either of the functions (from the lecture / from the file) to solve the tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following command simply imports all the methods from that code.\n",
    "from dist_erk import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading a corpus\n",
    "\n",
    "To train a distributional model, we first need a sufficiently large collection of texts which contain different words used frequently enough in different contexts. Here we will use a section of the Wikipedia corpus which you can download from [here](https://linux.dobnik.net/cloud/index.php/s/isMBj49jt5renYt?path=%2Fresources%2Fa2-distributional-representations) (wikipedia.txt.zip). (This file has been borrowed from another lab by [Richard Johansson](http://www.cse.chalmers.se/~richajo/)).  \n",
    "When unpacked, the file is 151mb, hence if you are using the MLT servers you should store it in a temporary folder outside your home and adjust the `corpus_dir` path below.  \n",
    "<!-- <It may already exist in `/opt/mlt/courses/cl2015/a5`.> -->\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#corpus_dir = '/Users/xilini/Desktop/wikipedia/'\n",
    "corpus_dir = 'wikipedia'\n",
    "#corpus_dir = 'C:/Users/bamsh/Desktop/assignment2extras/wikipedia'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Building a model\n",
    "\n",
    "Now you are ready to build the model.  \n",
    "Using the methods from the code imported above build three word matrices with 1000 dimensions as follows:  \n",
    "\n",
    "(i) with raw counts (saved to a variable `space_1k`);  \n",
    "(ii) with PPMI (`ppmispace_1k`);  \n",
    "(iii) with reduced dimensions SVD (`svdspace_1k`).  \n",
    "For the latter use `svddim=5`. **[5 marks]**\n",
    "\n",
    "Your task is to replace `...` with function calls. Functions are imported from `dist_erk.py` earlier, and they largely resemble functions shown during the lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading file wikipedia.txt\n",
      "create count matrices\n",
      "reading file wikipedia.txt\n",
      "ppmi transform\n",
      "svd transform\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "numdims = 1000\n",
    "svddim = 5\n",
    "\n",
    "# which words to use as targets and context words?\n",
    "# we need to count the words and keep only the N most frequent ones\n",
    "# which function would you use here with which variable?\n",
    "ktw = do_word_count(corpus_dir, numdims) #BL\n",
    "\n",
    "wi = make_word_index(ktw) # word index #BL\n",
    "words_in_order = sorted(wi.keys(), key=lambda w:wi[w]) # sorted words #BL\n",
    "\n",
    "# create different spaces (the original matrix space, the ppmi space, the svd space)\n",
    "# which functions with which arguments would you use here?\n",
    "print('create count matrices')\n",
    "space_1k = make_space(corpus_dir, wi, 1000) #BL\n",
    "print('ppmi transform')\n",
    "ppmispace_1k =  ppmi_transform(space_1k, wi) #BL\n",
    "print('svd transform')\n",
    "svdspace_1k = svd_transform(ppmispace_1k, numdims, svddim)\n",
    "print('done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house: [2554 3774 3105  567  962  631  443  185  311  189  131   28   93  169\n",
      "   81  125  151  408  194   90   79   29  217  184   62   15   31   70\n",
      "   10    1   41   21    1   31   37    1   30    5   25    7    3   20\n",
      "   11    1   32   36    2    5   66    4    0   46    8   18   28    0\n",
      "   20    7    8   16   10   40    0  175   10    2    7   19    1  174\n",
      "   11    3    1    6    0    0    0   10    9   11    7   24    4    4\n",
      "   14   23   58    7    0   10    2    3   10    6   18    6   13    3\n",
      "   22    0    3    5    3    7   14    3   40   20   19   15    6    8\n",
      "   24    4    5    1   19    0    3    1    0   14    0   14   53    7\n",
      "    7   11    6    5    5    4   12    6   53    1    1  433    4    0\n",
      "    5    7    7   12    1    1    3    4   17    8   16    1    2   31\n",
      "    1   12   14    1   44    6   14    9   38    7    2    6    8    1\n",
      "   10    6   10    1    9    7    9    4    3   10    0   11    3    2\n",
      "    0    2   11   37    2    0    2    1    5    9   10   16   88    6\n",
      "    0   21    1    1    0    2   47    3   27    7    0    2   13    1\n",
      "    2    0    5   31    0    1    0    3   10    0    1    0    3    3\n",
      "   17    1    1   16    3    7    4    7   15    4    0    0    2    5\n",
      "    0    2    0    5    0    9    0    0    8    0   10    0    0    0\n",
      "    2    0    1    3    1    3   15    1    9    0   19   14    0    0\n",
      "    3    2   18    3    1    3    2   19    5    2    4    1   10    6\n",
      "    0    3    3    6    4    2   25    4    6    3    1   25   10   15\n",
      "    3   10   15    1   10    1    8    1   13    1    2    9    9    1\n",
      "    4    1   25    0    4    6    5    5   36    0    2    2    2    0\n",
      "    0    2    3    3    0    1    4    6    5    0   50    2    5    2\n",
      "   14    6    2    2    4    1    9    4    5    3    1    0   12    3\n",
      "    3    2    2    0    0    1    4    7   12    5    0    2    1    2\n",
      "    3    4    7    3    5    0   29    7    1    1    0    3    3    3\n",
      "   10    0   14    2    0    2    4    6    0    5    0    0    1    1\n",
      "    4    1    1    0    0    0    0    3   20    0    0    2    1    5\n",
      "    3    8    3    5    1    2   66    1    2   19    2    1    3    3\n",
      "   21    5    4    2    2    0    4    3    5    0    7    1    6    1\n",
      "    3    3    1    0    3    0    2    0   89    2    3    1    1   14\n",
      "    0    2    1    9    2    3    2    4    2    0   25    0    0   23\n",
      "    0    6    2    1    3    0    2    5    0    4    4    3    0    4\n",
      "   58    3    1    6    2    4    3    3   11    1    1    1   10    0\n",
      "    7    3    1    6    1   18    1    0    4    2    0    8    5    2\n",
      "    0    0    0    0    5    1    2    1    1    3    1    2    1    1\n",
      "    0    6    1    4    1    3   20    1    0    5    2    5    2    1\n",
      "    0    0    0    2    6    1    1    0    1    1    1    0    0    3\n",
      "    3    0    0    6    6   74    3    0   13    5    2    2    1    5\n",
      "    3    3    1    7    4    0    0    2    3    0    4    0    4    1\n",
      "    0    2    5    2    1   14    2    0    0   19    0    1    2    1\n",
      "    0    3    2    0    0    3    1    3    3    2    7   18    7    6\n",
      "    6    0    1    9    1   10    2    0    2    0    2    4    0    0\n",
      "    1    2    0    1    0    2    0    0    0    2    1    2    2    0\n",
      "    3    2    2    0    0    1    2    3    1    1    1    2    0    0\n",
      "    3    0    7    2   39    0   14    0    1    1    0    1    5    3\n",
      "   11    0    3    0    1    1    0    0    1    9    2    1    0   11\n",
      "    1    3    7    0    0    0   32    1    0    0    0    1    1    3\n",
      "    0    9    0    2    0    1    3    2    6    0    3    0    0    2\n",
      "    3    0    1    0    1    4    0    0    1    1    0    0    5   21\n",
      "    2    1    1    3    0    1    7    1    3    4    0    5    3    0\n",
      "    7    2    0    4    2    0    2    1    4    4    0    0    0    5\n",
      "    3    2    2    0    4    0   23    2    2    2    4    0    1    0\n",
      "    4    0    3    5    3    0    8    0    1   16    1    2    2    7\n",
      "    0    0    1   11    1    0    4    0    1    0    1    2    1    5\n",
      "    0   97    0    2    0    3    0    8    1   14    4    9    2    3\n",
      "    1    1    0    3    4    0    5    1    5    2    0    0    0    2\n",
      "    1    2    1    1    1    1   12    0    2    5    1    0    0   13\n",
      "    2    0    0    0    2    2    0    0    3    1    1    1    1    0\n",
      "    1    2    1    0    0    0   10    0    1    0    1    1    1    1\n",
      "    0    1    0    0    3    2    5    0    0    2    1    0   23    0\n",
      "    0    4    0    1    0    0    0    1    1    2    1    0    1    0\n",
      "    0    4    1    0    1    1    5    1    1    0    1    0    0    0\n",
      "    1    0    0    2    2    3    0    1    0    4    3    3    1    4\n",
      "    0    0    0    6    1    2    1    0    5    3    0    0    1    2\n",
      "    0    5    0    0    2    1    1    4   15    0    0    1    1    3\n",
      "    1    0    1    4    1    1    2    8    1    3    0    0    0    0\n",
      "    1    3    2    1    0    1    0    2    0    0    0    0    1    1\n",
      "    0    1    3    7    0    0   42    4    0    1    2    3    1    0\n",
      "    1    3    2    0    0    4    0    0    0    4    2    0    0    8\n",
      "    2    0    1   15    0    0]\n"
     ]
    }
   ],
   "source": [
    "# now, to test the space, you can print vector representation for some words\n",
    "print('house:', space_1k['house'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oxford Advanced Dictionary has 185,000 words, hence 1,000 words is not representative. We trained a model with 10,000 words, and 50 dimensions on truncated SVD. It took 40 minutes on a laptop. We saved all three matrices [here](https://linux.dobnik.net/cloud/index.php/s/isMBj49jt5renYt?path=%2Fresources%2Fa2-distributional-representations) (pretrained.zip). Download them and unpack them to a `pretrained` folder which should be a subfolder of the folder with this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please wait...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "numdims = 10000\n",
    "svddim = 50\n",
    "\n",
    "print('Please wait...')\n",
    "ktw_10k       = np.load('./pretrained/ktw_wikipediaktw.npy', allow_pickle=True)\n",
    "space_10k     = np.load('./pretrained/raw_wikipediaktw.npy', allow_pickle=True).all()\n",
    "ppmispace_10k = np.load('./pretrained/ppmi_wikipediaktw.npy', allow_pickle=True).all()\n",
    "svdspace_10k  = np.load('./pretrained/svd50_wikipedia10k.npy', allow_pickle=True).all()\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "house: [2554 3774 3105 ...    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# testing semantic space\n",
    "print('house:', space_10k['house'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing semantic similarity\n",
    "\n",
    "The file `similarity_judgements.txt` (a copy is included with this notebook) contains 7,576 pairs of words and their lexical and visual similarities (based on the pictures) collected through crowd-sourcing using Mechanical Turk as described in [1]. The score range from 1 (highly dissimilar) to 5 (highly similar). Note: this is a different dataset from the phrase similarity dataset we discussed during the lecture (the one from [2]). For more information, please read the papers.\n",
    "\n",
    "The following code will transform similarity scores into a Python-friendly format:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of available words to test: 12\n",
      "number of available word pairs to test: 774\n"
     ]
    }
   ],
   "source": [
    "word_pairs = [] # test suit word pairs\n",
    "semantic_similarity = [] \n",
    "visual_similarity = []\n",
    "test_vocab = set()\n",
    "\n",
    "for index, line in enumerate(open('similarity_judgements.txt')):\n",
    "    data = line.strip().split('\\t')\n",
    "    if index > 0 and len(data) == 3:\n",
    "        w1, w2 = tuple(data[0].split('#'))\n",
    "        # it will check if both words from each pair exist in the word matrix.\n",
    "        if w1 in ktw_10k and w2 in ktw_10k:\n",
    "            word_pairs.append((w1, w2))\n",
    "            test_vocab.update([w1, w2])\n",
    "            semantic_similarity.append(float(data[1]))\n",
    "            visual_similarity.append(float(data[2]))\n",
    "        \n",
    "print('number of available words to test:', len(test_vocab-(test_vocab-set(ktw))))\n",
    "print('number of available word pairs to test:', len(word_pairs))\n",
    "#list(zip(word_pairs, visual_similarity, semantic_similarity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to test how the cosine similarity between vectors of each of the three spaces (normal space, ppmi, svd) compares with the human similarity judgements for the words in the similarity dataset. Which of the three spaces best approximates human judgements?\n",
    "\n",
    "For comparison of several scores, we can use [Spearman correlation coefficient](https://en.wikipedia.org/wiki/Spearman's_rank_correlation_coefficient) which is implemented in `scipy.stats.spearmanr` [here](https://docs.scipy.org/doc/scipy-0.19.0/reference/generated/scipy.stats.spearmanr.html). The values of the Sperman correlation coefficient range from -1, 0 to 1, where 0 indicates no correlation, 1 perfect correaltion and -1 negative correlation. Hence, the greater the number the better the similarity scores align. The p values tells us if the coefficient is statistically significant. For this to be the case, it must be less than or equal to $< 0.05$.\n",
    "\n",
    "Here is how you can calculate Pearson's correlation coefficient betweeen the scores of visual similarity and semantic similarity of the available words in the test suite:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Visual Similarity vs. Semantic Similarity:\n",
      "rho     = 0.7122\n",
      "p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "\n",
    "rho, pval = stats.spearmanr(semantic_similarity, visual_similarity)\n",
    "print(\"\"\"Visual Similarity vs. Semantic Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now calculate the cosine similarity scores of all word pairs in an ordered list using all three matrices. **[6 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print (\"with raw: \", cosine(\"stick\", \"sword\", space_10k)) #0.8225343344374068\n",
    "raw_similarities  = [cosine(w1, w2, space_10k) for w1, w2 in word_pairs]\n",
    "ppmi_similarities = [cosine(w1, w2, ppmispace_10k) for w1, w2 in word_pairs]\n",
    "svd_similarities  = [cosine(w1, w2, svdspace_10k) for w1, w2 in word_pairs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, calculate correlation coefficients between lists of similarity scores and the real semantic similarity scores from the experiment. The scores of what model best correlates them? Is this expected? **[6 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Similarity vs. Semantic Similarity:\n",
      "rho     = 0.1522\n",
      "p-value = 0.0000\n",
      "PPMI Similarity vs. Semantic Similarity:\n",
      "rho     = 0.4547\n",
      "p-value = 0.0000\n",
      "SVD Similarity vs. Semantic Similarity:\n",
      "rho     = 0.4232\n",
      "p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "# your code should go here\n",
    "rho, pval = stats.spearmanr(raw_similarities, semantic_similarity)\n",
    "print(\"\"\"Raw Similarity vs. Semantic Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))\n",
    "\n",
    "rho, pval = stats.spearmanr(ppmi_similarities, semantic_similarity)\n",
    "print(\"\"\"PPMI Similarity vs. Semantic Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))\n",
    "\n",
    "rho, pval = stats.spearmanr(svd_similarities, semantic_similarity)\n",
    "print(\"\"\"SVD Similarity vs. Semantic Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* comment:\n",
    "    The PPMI Similarity versus the Semantic Similarity returned the most accurate of pairs, the value being: 0.4547. We see that the SVD Similarity comes next, with its rho value: 0.4232. Following PPMI and SVD similarities, comes the correlation coefficient (rho) for raw similarity with a value of 0.1522."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also calculate correlation coefficients between lists of cosine similarity scores and the real visual similarity scores from the experiment. Which similarity model best correlates with them? How do the correlation coefficients compare with those from the previous comparison - and can you speculate why do we get such results? **[7 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw Similarity vs. Visual Similarity:\n",
      "rho     = 0.1212\n",
      "p-value = 0.0007\n",
      "\n",
      "\n",
      "\n",
      "PPMI Similarity vs. Visual Similarity:\n",
      "rho     = 0.3838\n",
      "p-value = 0.0000\n",
      "\n",
      "\n",
      "\n",
      "SVD Similarity vs. Visual Similarity:\n",
      "rho     = 0.3097\n",
      "p-value = 0.0000\n"
     ]
    }
   ],
   "source": [
    "#Raw Similarities versus Visual Similarities:\n",
    "rho, pval = stats.spearmanr(raw_similarities, visual_similarity)\n",
    "print(\"\"\"Raw Similarity vs. Visual Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))\n",
    "\n",
    "print (\"\\n\\n\")\n",
    "\n",
    "\n",
    "#PPMI Similarities versus Visual Similarities:\n",
    "rho, pval = stats.spearmanr(ppmi_similarities, visual_similarity)\n",
    "print(\"\"\"PPMI Similarity vs. Visual Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))\n",
    "\n",
    "print (\"\\n\\n\")\n",
    "\n",
    "\n",
    "#SVD Similarities versus Visual Similarities:\n",
    "rho, pval = stats.spearmanr(svd_similarities, visual_similarity)\n",
    "print(\"\"\"SVD Similarity vs. Visual Similarity:\n",
    "rho     = {:.4f}\n",
    "p-value = {:.4f}\"\"\".format(rho, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    We can note that the pairs consisting of Semantic similarity lists have higher rho values and thus showing more similarity than the pairs consisting of Visual similarity lists in this section. Considering that we prepared the three spaces based on text models and the lexical items in the corpus, we can justify this result, that is, spaces based on words can compare better to semantic similarities based on text rather than visual images reviewed by the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Operations on similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can perform mathematical operations on vectors to derive meaning predictions. For example, we can subtract the normalised vectors for `king` minus `queen` and add the resulting vector to `man` and we hope to get the vector for `woman`. Why? **[3 marks]**"
   ]
  },
  {
   "attachments": {
    "manWomanKingQueen.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your answer should go here:**\n",
    "![manWomanKingQueen.png](attachment:manWomanKingQueen.png)\n",
    "(image from https://medium.com/riga-data-science-club/word-embeddings-by-example-9b067c1d0d33)\n",
    "\n",
    "Since the difference between the vectors for king and queen is most likely the same difference between man and woman, we can do mathematical operations to derive meaning prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some helpful code that allows us to calculate such comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "def normalize(vec):\n",
    "    return vec / veclen(vec)\n",
    "\n",
    "def find_similar_to(vec1, space):\n",
    "    # vector similarity funciton\n",
    "    #sim_fn = lambda a, b: 1-distance.euclidean(normalize(a), normalize(b))\n",
    "    #sim_fn = lambda a, b: 1-distance.correlation(a, b)\n",
    "    #sim_fn = lambda a, b: 1-distance.cityblock(normalize(a), normalize(b))\n",
    "    #sim_fn = lambda a, b: 1-distance.chebyshev(normalize(a), normalize(b))\n",
    "    #sim_fn = lambda a, b: np.dot(normalize(a), normalize(b))\n",
    "    sim_fn = lambda a, b: 1-distance.cosine(a, b)\n",
    "\n",
    "    sims = [\n",
    "        (word2, sim_fn(vec1, space[word2]))\n",
    "        for word2 in space.keys()\n",
    "    ]\n",
    "    return sorted(sims, key = lambda p:p[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is how you apply this code. Comment on the results you get. **[3 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for raw space:\n",
      "[('long', 0.936140411029304), ('just', 0.9049060246775732), ('normal', 0.897070493693546), ('child', 0.8968235510083787), ('universal', 0.8954682113733906), ('genius', 0.8941840695017294), ('unit', 0.8939911177435964), ('bird', 0.893943608600412), ('light', 0.8930841816879834), ('radical', 0.8928522776983006)]\n",
      "for PPMI space:\n",
      "[('long', 0.6455903190370874), ('light', 0.5756309144130762), ('short', 0.22665051391680424), ('about', 0.2062232575609404), ('around', 0.20341064658972596), ('than', 0.1997623801104953), ('longer', 0.19775518996857122), ('through', 0.19530678790677225), ('each', 0.19315737065635885), ('a', 0.1897425288444996)]\n",
      "for SVD space:\n",
      "[('long', 0.8733111261346901), ('above', 0.8259671977311955), ('around', 0.8030776291120685), ('sun', 0.7692439111243973), ('just', 0.7678481974778111), ('wide', 0.767257431992253), ('each', 0.7665960260861158), ('circle', 0.7647746702909336), ('length', 0.7601066921319761), ('almost', 0.7542351860536628)]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'BL_update king queen man woman note'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''BL_update for all 3 spaces'''\n",
    "\n",
    "short = normalize(space_10k['short'])\n",
    "light = normalize(space_10k['light'])\n",
    "long = normalize(space_10k['long'])\n",
    "heavy = normalize(space_10k['heavy'])\n",
    "print (\"for raw space:\")\n",
    "sims = find_similar_to(light - (heavy - long), space_10k)[:10]\n",
    "print (sims)\n",
    "\n",
    "short = normalize(ppmispace_10k['short'])\n",
    "light = normalize(ppmispace_10k['light'])\n",
    "long = normalize(ppmispace_10k['long'])\n",
    "heavy = normalize(ppmispace_10k['heavy'])\n",
    "print (\"for PPMI space:\")\n",
    "sims = find_similar_to(light - (heavy - long), ppmispace_10k)[:10]\n",
    "print(sims)\n",
    "\n",
    "short = normalize(svdspace_10k['short'])\n",
    "light = normalize(svdspace_10k['light'])\n",
    "long = normalize(svdspace_10k['long'])\n",
    "heavy = normalize(svdspace_10k['heavy'])\n",
    "print (\"for SVD space:\")\n",
    "sims = find_similar_to(light - (heavy - long), svdspace_10k)[:10]\n",
    "print(sims)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    My guess is that if we have good Correlation Coefficients resulted from our lists then it is possible to predict various phenomena such as antonyms, discussion contexts, in the same way we find similarities between words. We can use linear algebra operations on sets that are presentable in mathematical spaces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find 5 similar pairs of pairs of words and test them. Hint: Google for `word analogies examples`. You can also construct analogies that are less lexical but more grammatical, e.g. `see, saw, leave, ?` or analogies that are based on world knowledge as in the [Google analogy dataset](http://download.tensorflow.org/data/questions-words.txt) from [3]. Does the resulting vector similarity confirm your expectations? But remember you can only do this if the words are contained in our vector space with 10,000 dimensions. **[10 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'helicopter' and 'jet'\n",
      "'airplane' then:\n",
      "('helicopter', 0.9370550278966456)\n",
      "('airplane', 0.9215108423296754)\n",
      "('craft', 0.8941106310648328)\n",
      "('crews', 0.8839852541527036)\n",
      "('boat', 0.8836199694871517)\n",
      "('boats', 0.8710809738484855)\n",
      "('helicopters', 0.863978010410358)\n",
      "('submarines', 0.8622751191535338)\n",
      "('patrol', 0.8469179924650048)\n",
      "('submarine', 0.8463454607238514)\n",
      "\n",
      "\n",
      "\n",
      "'corn' and 'rice'\n",
      "'apple' then:\n",
      "('apple', 0.8977378691903365)\n",
      "('intel', 0.8784277897113222)\n",
      "('ipod', 0.8229007239811266)\n",
      "('console', 0.8163403486272348)\n",
      "('atari', 0.8162063945256424)\n",
      "('microsoft', 0.8159230930052944)\n",
      "('xbox', 0.8102871988080017)\n",
      "('sony', 0.8070048384972651)\n",
      "('amd', 0.8059876823676014)\n",
      "('nintendo', 0.8039671018466545)\n",
      "\n",
      "\n",
      "\n",
      "'bus' and 'truck'\n",
      "'bus' then:\n",
      "('bus', 0.8845658108393816)\n",
      "('terminal', 0.8122254905203837)\n",
      "('network', 0.7867169074313085)\n",
      "('transit', 0.7648003177547797)\n",
      "('rail', 0.7594777048921911)\n",
      "('cable', 0.757319657089172)\n",
      "('telephone', 0.7542540504373751)\n",
      "('connecting', 0.7534373445036096)\n",
      "('subway', 0.75169853863082)\n",
      "('wireless', 0.7430118280132082)\n",
      "\n",
      "\n",
      "\n",
      "'guitar' and 'trumpet'\n",
      "'key' then:\n",
      "('key', 0.9190378671276764)\n",
      "('own', 0.8150999080722288)\n",
      "('current', 0.8085543054820327)\n",
      "('main', 0.8062581420912239)\n",
      "('certain', 0.8060702051419566)\n",
      "('particular', 0.8034137283120187)\n",
      "('primary', 0.8005609715908554)\n",
      "('existing', 0.7919529885299188)\n",
      "('both', 0.7916613878841019)\n",
      "('real', 0.7913243349863135)\n",
      "\n",
      "\n",
      "\n",
      "'eagle' and 'fox'\n",
      "'donkey' then:\n",
      "('gif', 0.762219184861827)\n",
      "('eagle', 0.7593486398393796)\n",
      "('tiger', 0.7443583137902734)\n",
      "('elephant', 0.7331499723055989)\n",
      "('pocket', 0.7303343570684733)\n",
      "('flower', 0.7282793449555653)\n",
      "('leaf', 0.7117160236351012)\n",
      "('dragon', 0.703301522350716)\n",
      "('giant', 0.7024331867540712)\n",
      "('donkey', 0.6994164323044818)\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Your code should go here...\n",
    "\n",
    "def based_on_pair_return_similar_to_word(pair1_word1, pair1_word2, pair2_word1):\n",
    "    print (\"'\" + pair1_word1 + \"' and '\" + pair1_word2 + \"'\" )\n",
    "    print (\"'\" + pair2_word1 + \"' then:\")\n",
    "    pair1_word1 = normalize(svdspace_10k[pair1_word1])\n",
    "    pair1_word2 = normalize(svdspace_10k[pair1_word2])\n",
    "    pair2_word1 = normalize(svdspace_10k[pair2_word1])\n",
    "    result = find_similar_to(pair1_word1 - pair1_word2 + pair2_word1, svdspace_10k)[:10] #BL_update b1-a1+a2\n",
    "    #BL_update do for all 3 spaces: raw, ppmi, svd\n",
    "    for i, word_and_cosSim in enumerate (result):\n",
    "        print (word_and_cosSim)\n",
    "    print (\"\\n\\n\")\n",
    "    \n",
    "based_on_pair_return_similar_to_word(\"helicopter\", \"jet\", \"airplane\") #expected truck\n",
    "based_on_pair_return_similar_to_word(\"corn\", \"rice\", \"apple\") #expected peach\n",
    "based_on_pair_return_similar_to_word(\"bus\", \"truck\", \"bus\") #expected train\n",
    "based_on_pair_return_similar_to_word(\"guitar\", \"trumpet\", \"key\") #expected piano\n",
    "based_on_pair_return_similar_to_word(\"eagle\", \"fox\", \"donkey\") #expected horse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Semantic composition and phrase similarity **[20 marks]**\n",
    "\n",
    "In this task, we are going to look at how different semantic composition models, introduced in [2] correlate with human judgements. The file with the dataset is `mitchell_lapata_acl08.txt` included with this notebook. Your task is to do the following:  \n",
    "\n",
    "(i) process the dataset, extract pairs of `reference - landmark high` and `reference - landmark low`; you can use the code from the lecture as something to start with. Note that there are 2 landmarks for each reference: one landmark exhibits high similarity with the reference, while another one has low similarity with the reference. A single human participant could have evaluated both of these pairs. For more details, we refer you to the paper.  \n",
    "\n",
    "(ii) build models of semantic phrase composition: in the lecture we introduced simple additive, simple multiplicative and combined models (details are in [2]). Your task is to take a single pair (a reference or a high similarity landmark or a low similarity landmark) and compute the composition of its vectors using each of these functions. Thus, you will have three compositional models that take a `noun - verb` pair and output a single vector, representing the meaning of this pair. As your semantic space, you can use pretrained spaces (standard space, ppmi or svd) introduced above. It is up to you which space you use, but for someone who runs your code, it should be pretty straightforward to switch between them.\n",
    "\n",
    "(iii) calculate Spearman correlation between each model's predictions and human judgements; you should have something similar to the scores that are shown in the paper [2]:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![title](./res.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper states that they calculated correlations between each individual participant's judgeements and each model's predictions.  \n",
    "\n",
    "Let's say we have 3 models: simple additive (A), simple multiplicative (M), combined (C).  \n",
    "From our task dataset, we also know that we have 20 participants.  \n",
    "Now, for each participant in 20 participants we get all `verb - noun` pairs that these participated evaluated.  \n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_judgemenets_example = [\n",
    " 'participant50 chatter child gabble 6 high',\n",
    " 'participant50 chatter tooth click 2 high',\n",
    " 'participant50 reel head whirl 5 high',\n",
    " 'participant50 reel mind stagger 4 low',\n",
    " 'participant50 reel industry stagger 5 high',\n",
    " 'participant50 reel man whirl 3 low',\n",
    " 'participant50 glow fire beam 7 low',\n",
    " 'participant50 glow face burn 3 low',\n",
    " 'participant50 glow cigar burn 5 high',\n",
    " 'participant50 glow skin beam 7 high'\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "participant_judgemenets_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first pair that participant50 evaluated: reference `child chatter` and high-level similarity landmark (as the last word in the row indicates) `child gabble`. The human gave the similarity score of 6 (very similar). Thus, human similarity judgment = [6].  \n",
    "\n",
    "Our A model's output:  \n",
    "cosine(p1, p2) = 0.88, where p1 is the result of addition of word vectors in the reference phrase `child gabble`, and p2 is the result of addition of word vectors in the high-level similarity phrase `child chatter`.  \n",
    "\n",
    "Therefore, we have human rating vector [6] and model A output [0.88]. Next is to compute correlation between these two vectors.\n",
    "\n",
    "To get an overall score, simply average your correlation scores over all participants, since you are calculating correlation scores per participant.\n",
    "\n",
    "Of course, your human rating vectors will be longer (e.g., [6, 7, 3, 4, 5]) where each element is a participant's judgement of a specific pair. Each of your models (A, B, C) will produce a single vector of cosine similarity between these same pairs (e.g., [0.89, 0.98, 0.23, 0.65, 0.55]). The goal is to compare each model's cosine similarity vectors with human rating vectors and identify the model which outputs the best result in terms of being the closest to the way human rate similarity between the phrases.\n",
    "\n",
    "The minimum to do in this task: compute correlations for 3 models mentioned above and human rating for AT LEAST one participant. Elaborate on how different the resulting correlation scores are depending on the model's composition function (additive, multiplicative, combined). For examples on how to interpret the results, look at Section 5 Results of the original paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code should go here\n",
    "\n",
    "dataset = {}\n",
    "references = []\n",
    "\n",
    "with open('mitchell_lapata_acl08.txt', 'r') as f:\n",
    "    phrase_dataset = f.read().splitlines()\n",
    "    for line in phrase_dataset[1:]:\n",
    "        participant_id, reference, noun, landmark, rating, hilo = line.split()\n",
    "        \n",
    "        reference_phrase = [noun, reference]\n",
    "\n",
    "        if reference_phrase not in references:\n",
    "            references.append(reference_phrase)\n",
    "\n",
    "        landmark_phrase = [noun, landmark]\n",
    "\n",
    "        if participant_id not in dataset:\n",
    "            dataset[participant_id] = []\n",
    "        else:\n",
    "            dataset[participant_id].append((reference_phrase, landmark_phrase, rating, hilo))\n",
    "dataset[\"participant50\"]\n",
    "\n",
    "#for i,participant in enumerate(dataset):\n",
    "    #print (participant)\n",
    "    #print (dataset[participant])\n",
    "\n",
    "#print (references)\n",
    "\n",
    "#print (dataset[\"participant20\"])\n",
    "#for i in dataset[\"participant20\"]:\n",
    "#    print (i)\n",
    "#    if i[3] == \"high\":\n",
    "#        print (\"high\")\n",
    "\n",
    "def veclen(vector):\n",
    "    return math.sqrt(np.sum(np.square(vector)))\n",
    "\n",
    "def cosine(vector1, vector2):\n",
    "    veclen1 = veclen(vector1)\n",
    "    veclen2 = veclen(vector2)\n",
    "    if veclen1 == 0.0 or veclen2 == 0.0:\n",
    "        # one of the vectors is empty, the cosine is 0\n",
    "        return 0.0\n",
    "    else:\n",
    "        # we could also simply do:\n",
    "        dotproduct = np.dot(vector1, vector2)\n",
    "        return dotproduct / (veclen1 * veclen2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''BL update: pretrained ktw ppk, raw, etc. (Sigrid's) ktw_\n",
    "calculate_corelation\n",
    "the models for each of raw, svd, ppmi\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['face', 'glow']\n"
     ]
    }
   ],
   "source": [
    "example_phrase = references[-3]\n",
    "print(example_phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject_space = our_space[example_phrase[0]]\n",
    "verb_space = our_space[example_phrase[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_phrase_space(phrase, x_names):\n",
    "\n",
    "    # first we get representations for verb and noun\n",
    "    subject_space = our_space[phrase[0]]\n",
    "    verb_space = our_space[phrase[1]]\n",
    "    # representation for house and burn\n",
    "    \n",
    "    representation = np.zeros(len(x_names))\n",
    "\n",
    "    for n, word in enumerate(x_names.keys()):\n",
    "\n",
    "        # I get v^Ith element from each of the vectors\n",
    "        subject_value = subject_space[word][0]\n",
    "        verb_value = verb_space[word][0]\n",
    "\n",
    "        #out = subject_value + verb_value\n",
    "        #out = subject_value * verb_value\n",
    "        \n",
    "        # 6 and 0, if we do summation, we are getting 6\n",
    "        # if we do mulitplication, we are getting 0\n",
    "        \n",
    "        #out = subject_value * 0.2 + verb_value * 0.8\n",
    "        #out = subject_value * 0.0 + verb_value * 0.95 + (0.05 * subject_value * verb_value)\n",
    "\n",
    "        representation[n] = out\n",
    "\n",
    "    return representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_phrase_space' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-5f977b805191>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlandmark_low\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'face'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'burn'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mref\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_phrase_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreference\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mlhigh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_phrase_space\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlandmark_high\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_phrase_space' is not defined"
     ]
    }
   ],
   "source": [
    "reference = ['face', 'glow']\n",
    "landmark_high = ['face', 'beam']\n",
    "landmark_low = ['face', 'burn']\n",
    "\n",
    "ref = build_phrase_space(reference, dims)\n",
    "\n",
    "lhigh = build_phrase_space(landmark_high, dims)\n",
    "\n",
    "llow = build_phrase_space(landmark_low, dims)\n",
    "\n",
    "\n",
    "print(ref, ref.shape)\n",
    "print(lhigh)\n",
    "print(llow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Any comments/thoughts should go here:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Literature\n",
    "\n",
    "  - [1] C. Silberer and M. Lapata. Learning grounded meaning representations with autoencoders. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 721–732, Baltimore, Maryland, USA, June 23–25 2014 2014. Association for Computational Linguistics.  \n",
    "\n",
    "  - [2] Mitchell, J., & Lapata, M. (2008). Vector-based Models of Semantic Composition. In Proceedings of ACL-08: HLT (pp. 236–244). Association for Computational Linguistics.\n",
    "  \n",
    "  - [3] T. Mikolov, I. Sutskever, K. Chen, G. S. Corrado, and J. Dean. Distributed representations of words and phrases and their compositionality. In Advances in neural information processing systems, pages 3111–3119, 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marks\n",
    "\n",
    "This assignment has a total of 60 marks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
