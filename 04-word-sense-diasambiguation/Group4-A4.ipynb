{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguation using Neural Networks\n",
    "Adam Ek\n",
    "\n",
    "----------------------------------\n",
    "\n",
    "The lab is an exploration and learning exercise to be done in a group and also in discussion with the teachers and other students.\n",
    "\n",
    "Before starting, please read the instructions on [how to work on group assignments](https://github.com/sdobnik/computational-semantics/blob/master/README.md).\n",
    "\n",
    "Write all your answers and the code in the appropriate boxes below.\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A problem with static distributional vectors is the difficulty of distinguishing between different *word senses*. We will continue our exploration of word vectors by considering *trainable vectors* or *word embeddings* for Word Sense Disambiguation (WSD).\n",
    "\n",
    "The goal of word sense disambiguation is to train a model to find the sense of a word (homonyms of a word-form). For example, the word \"bank\" can mean \"sloping land\" or \"financial institution\". \n",
    "\n",
    "(a) \"I deposited my money in the **bank**\" (financial institution)\n",
    "\n",
    "(b) \"I swam from the river **bank**\" (sloping land)\n",
    "\n",
    "In case a) and b) we can determine that the meaning of \"bank\" based on the *context*. To utilize context in a semantic model we use *contextualized word representations*. Previously we worked with *static word representations*, i.e. the representation does not depend on the context. To illustrate we can consider sentences (a) and (b), the word **bank** would have the same static representation in both sentences, which means that it becomes difficult for us to predict its sense. What we want is to create representations that depend on the context, i.e. *contextualized embeddings*. \n",
    "\n",
    "We will create contextualized embeddings with Recurrent Neural Networks. You can read more about recurrent neural netoworks [here](https://colah.github.io/posts/2015-08-Understanding-LSTMs/). Your overall task in this lab is to create a neural network model that can disambiguate the word sense of 15 different words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we import some packages that we need\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchtext\n",
    "\n",
    "# our hyperparameters (add more when/if you need them)\n",
    "device = torch.device('cuda:3')\n",
    "\n",
    "batch_size = 128\n",
    "learning_rate = 0.001\n",
    "epochs = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Working with data\n",
    "\n",
    "A central part of any machine learning system is the data we're working with. In this section we will split the data (the dataset is located here: ``wsd-data/wsd_data.txt``) into a training set and a test set. We will also create a baseline to compare our model against. Finally, we will use TorchText to transform our data (raw text) into a convenient format that our neural network can work with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "The dataset we will use contain different word sense for 15 different words. The data is organized as follows (values separated by tabs): \n",
    "- Column 1: word-sense\n",
    "- Column 2: word-form\n",
    "- Column 3: index of word\n",
    "- Column 4: white-space tokenized context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the data\n",
    "\n",
    "Your first task is to seperate the data into a *training set* and a *test set*. The training set should contain 80% of the examples and the test set the remaining 20%. The examples for the test/training set should be selected **randomly**. Save each dataset into a .csv file for loading later. **[2 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "from math import floor\n",
    "\n",
    "def data_split(path_to_dataset, split = 0.8):\n",
    "    '''Splits txt into random 80:20 subsets and saves them as csv'''\n",
    "    \n",
    "    #Shuffle and split\n",
    "    with open(path_to_dataset, encoding='utf8') as f:\n",
    "        lines = [l for l in f]\n",
    "        shuffle(lines)\n",
    "        split_index = floor(len(lines) * split)\n",
    "        training,testing = lines[:split_index],lines[split_index:]\n",
    "     \n",
    "    #Save training csv\n",
    "    with open(path_to_dataset.replace('.txt', '-train.csv'), 'w', encoding='utf8') as f:\n",
    "        for l in training:\n",
    "            f.write(l)\n",
    "            \n",
    "    #Save testing csv\n",
    "    with open(path_to_dataset.replace('.txt', '-test.csv'), 'w', encoding='utf8') as f:\n",
    "        for l in testing:\n",
    "            f.write(l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a baseline\n",
    "\n",
    "Your second task is to create a *baseline* for the task. A baseline is a \"reality check\" for a model, given a very simple heuristic/algorithmic/model solution to the problem, can our neural network perform better than this?\n",
    "The baseline you are to create is the \"most common sense\" (MCS) baseline. For each word form, find the most commonly assigned sense to the word, and label a words with that sense. **[2 marks]**\n",
    "\n",
    "E.g. In a fictional dataset, \"bank\" have two senses, \"financial institution\" which occur 5 times and \"side of river\" 3 times. Thus, all 8 occurences of bank is labeled \"financial institution\" and this yields an MCS accuracy of 5/8 = 62.5%. If a model obtain a higher score than this, we can conclude that the model *at least* is better than selecting the most frequent word sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'keep': {'mcs': 0.3919896161691081, 'senses': 11},\n",
       " 'national': {'mcs': 0.20456663560111835, 'senses': 6},\n",
       " 'build': {'mcs': 0.21202404809619238, 'senses': 10},\n",
       " 'place': {'mcs': 0.2428793371310202, 'senses': 7},\n",
       " 'position': {'mcs': 0.20171094101755965, 'senses': 6},\n",
       " 'serve': {'mcs': 0.1551155115511551, 'senses': 9},\n",
       " 'hold': {'mcs': 0.15195137555982086, 'senses': 11},\n",
       " 'line': {'mcs': 0.8512173128944995, 'senses': 11},\n",
       " 'see': {'mcs': 0.6275619455490976, 'senses': 11},\n",
       " 'time': {'mcs': 0.27864214992927866, 'senses': 5},\n",
       " 'physical': {'mcs': 0.23641160949868073, 'senses': 6},\n",
       " 'follow': {'mcs': 0.14589020321504398, 'senses': 11},\n",
       " 'regular': {'mcs': 0.21732522796352582, 'senses': 8},\n",
       " 'bad': {'mcs': 0.6073903002309469, 'senses': 4},\n",
       " 'force': {'mcs': 0.16273156556483837, 'senses': 8},\n",
       " 'professional': {'mcs': 0.21756487025948104, 'senses': 5},\n",
       " 'security': {'mcs': 0.2033271719038817, 'senses': 7},\n",
       " 'positive': {'mcs': 0.35444078947368424, 'senses': 5},\n",
       " 'point': {'mcs': 0.35546262415054886, 'senses': 8},\n",
       " 'common': {'mcs': 0.2505733944954128, 'senses': 4},\n",
       " 'find': {'mcs': 0.23176323468111712, 'senses': 10},\n",
       " 'life': {'mcs': 0.22466137319009807, 'senses': 9},\n",
       " 'order': {'mcs': 0.21956087824351297, 'senses': 5},\n",
       " 'bring': {'mcs': 0.21170809943865276, 'senses': 8},\n",
       " 'active': {'mcs': 0.3204172876304024, 'senses': 5},\n",
       " 'extend': {'mcs': 0.1802610114192496, 'senses': 7},\n",
       " 'case': {'mcs': 0.2037351443123939, 'senses': 8},\n",
       " 'lead': {'mcs': 0.17967830521773245, 'senses': 8},\n",
       " 'critical': {'mcs': 0.2744097000638162, 'senses': 5},\n",
       " 'major': {'mcs': 0.3032514930325149, 'senses': 4}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def mcs_baseline(data):\n",
    "    words = {}\n",
    "    with open(data, encoding='utf8') as f:\n",
    "        for l in f:\n",
    "            sense, form, idx, context = l.split('\\t')\n",
    "            if form not in words:\n",
    "                words[form] = {}\n",
    "            words[form][sense] = words[form].get(sense,0)+1\n",
    "    \n",
    "    words_baseline = {}\n",
    "    for form, senses in words.items():\n",
    "        mostcommon, freq = sorted(senses.items(), key= lambda item:item[1], reverse=True)[0]\n",
    "        total_freqs = sum(senses.values())\n",
    "        baseline = freq/total_freqs  #Occurrence of the most common sense / occurrances of all senses\n",
    "        wdict = words_baseline[form[:form.index('.')] ] = {}\n",
    "        wdict['mcs'] = baseline\n",
    "        wdict['senses'] = len(senses)\n",
    "    \n",
    "    return words_baseline\n",
    "\n",
    "mcs_baseline('wsd-data/wsd_data.txt') # key:value = lemma:MCS (ie, Most common sense count / All senses counts )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating data iterators\n",
    "\n",
    "To train a neural network, we first need to prepare the data. This involves converting words (and labels) to a number, and organizing the data into batches. We also want the ability to shuffle the examples such that they appear in a random order.  \n",
    "\n",
    "To do all of this we will use the torchtext library (https://torchtext.readthedocs.io/en/latest/index.html). In addition to converting our data into numerical form and creating batches, it will generate a word and label vocabulary, and data iterators than can sort and shuffle the examples. \n",
    "\n",
    "Your task is to create a dataloader for the training and test set you created previously. So, how do we go about doing this?\n",
    "\n",
    "1) First we create a ``Field`` for each of our columns. A field is a function which tokenize the input, keep a dictionary of word-to-numbers, and fix paddings. So, we need four fields, one for the word-sense, one for the position, one for the lemma and one for the context. \n",
    "\n",
    "2) After we have our fields, we need to process the data. For this we use the ``TabularDataset`` class. We pass the name and path of the training and test files we created previously, then we assign which field to use in each column. The result is that each column will be processed by the field indicated. So, the context column will be tokenized and processed by the context field and so on. \n",
    "\n",
    "3) After we have processed the dataset we need to build the vocabulary, for this we call the function ``build_vocab()`` on the different ``Fields`` with the output from ``TabularDataset`` as input. This looks at our dataset and creates the necessary vocabularies (word-to-number mappings). \n",
    "\n",
    "4) Finally, the last step. In the last step we load the data objects given by the ``TabularDataset`` and pass it to the ``BucketIterator`` class. This class will organize our examples into batches and shuffle them around (such that for each epoch the model observe the examples in a different order). When we are done with this we can let our function return the data iterators and vocabularies, then we are ready to train and test our model!\n",
    "\n",
    "Implement the dataloader. [**2 marks**]\n",
    "\n",
    "*hint: for TabularDataset and BucketIterator use the class function splits()* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext.data import Field, BucketIterator, TabularDataset\n",
    "def dataloader(path, batch_size=8):\n",
    "    #Fields: word-sense, lemma, position,  context\n",
    "    Tokens = torchtext.data.Field(tokenize=lambda x:x.split(), lower=True, batch_first=True) #TODO lowercase?\n",
    "    Labels = torchtext.data.Field(batch_first=True) #TODO trim \".pos\" or not?\n",
    "    \n",
    "    fields = [('sense',Labels),('lemma',Tokens),('position',Tokens),('context',Tokens)]\n",
    "    \n",
    "    #Process from csv files\n",
    "    train,test = torchtext.data.TabularDataset.splits(\n",
    "            path=path, train='wsd_data-train.csv', test='wsd_data-test.csv',\n",
    "            format='csv', fields=fields, skip_header=False, \n",
    "            csv_reader_params = {'delimiter':'\\t','quotechar':'ã€'})\n",
    "    \n",
    "    #Build vocab\n",
    "    Labels.build_vocab(train) # nr of classes\n",
    "    Tokens.build_vocab(train)\n",
    "\n",
    "    #Batch iterator\n",
    "    train_iter,test_iter = torchtext.data.BucketIterator.splits(\n",
    "            (train,test), batch_size=batch_size, shuffle=True, device=device,\n",
    "             sort_within_batch=True, sort_key=lambda x: len(x.context))\n",
    "    \n",
    "    return train_iter, test_iter, Tokens.vocab, Labels.vocab\n",
    "        #  train_iter, test_iter, vocab, labels  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 Creating and running a Neural Network for WSD\n",
    "\n",
    "In this section we will create and run a neural network to predict word senses based on *contextualized representations*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n",
    "\n",
    "We will use a bidirectional Long-Short-Term Memory (LSTM) network to create a representation for the sentences and a Linear classifier to predict the sense of each word.\n",
    "\n",
    "When we initialize the model, we need a few things:\n",
    "\n",
    "    1) An embedding layer: a dictionary from which we can obtain word embeddings\n",
    "    2) A LSTM-module to obtain contextual representations\n",
    "    3) A classifier that compute scores for each word-sense given *some* input\n",
    "\n",
    "\n",
    "The general procedure is the following:\n",
    "\n",
    "    1) For each word in the sentence, obtain word embeddings\n",
    "    2) Run the embedded sentences through the RNN\n",
    "    3) Select the appropriate hidden state\n",
    "    4) Predict the word-sense \n",
    "\n",
    "**Suggestion for efficiency:**  *Use a low dimensionality (32) for word embeddings and the LSTM when developing and testing the code, then scale up when running the full training/tests*\n",
    "    \n",
    "Your tasks will be to create two different models (both follow the two outlines described above), described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first approach to WSD, you are to select the index of our target word (column 3 in the dataset) and predict the word sense. **[5 marks]**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO model:  given lemma/word at position in context => which word sense \n",
    "#                                                      (out of 224 senses or out of the set of given word senses?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Given the index of target word (column 3 in the dataset) => predict the word sense\n",
    "#  QUE: the index number or the 'indexed token'?\n",
    "\n",
    "def get_target_token(bat):\n",
    "    '''Given the index \"n\" from column 3, select the nth token in the context sequence.'''\n",
    "    ctx, position = bat.context, bat.position\n",
    "    targets=[]\n",
    "    for n in range(len(bat)):\n",
    "        seq = ctx[n] #the nth context seq in each batch\n",
    "        target_i = vocab.itos[position[n]] \n",
    "        target_i = int(target_i) # the index integer for the target token in the nth seq\n",
    "        target_token = seq[target_i]\n",
    "        targets.append([target_token])\n",
    "\n",
    "    return torch.tensor(targets).to(device) # B,1 where dim1 is the target token index\n",
    "\n",
    "class WSDModel_approach1(nn.Module):\n",
    "    def __init__(self, vocab_dim, num_senses, h_dim):\n",
    "        super(WSDModel_approach1, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_dim, h_dim)\n",
    "        self.rnn = nn.LSTM(h_dim, h_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(h_dim, num_senses) # TODO total senses or a word's senses?\n",
    "#         self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        # Select column 3 => Index the ith token in the context        \n",
    "        batch_targets = get_target_token(batch) # B,1\n",
    "        \n",
    "        #Embed the input\n",
    "        embedded = self.embeddings(batch_targets) # B,1,HD\n",
    "        \n",
    "        #Put the embeddings through RNN\n",
    "        rep, (_, _) = self.rnn(embedded)\n",
    "#         rep = self.dropout(rep)\n",
    "        \n",
    "        # Predict the class from RNN output\n",
    "        predictions = self.classifier(rep)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the second approach to WSD, you are to predict the word sense based on the final hidden state given by the RNN. **[5 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given \"final hidden state of RNN\" => predict word sense\n",
    "class WSDModel_approach2(nn.Module):\n",
    "    def __init__(self, vocab_dim, num_senses, h_dim):\n",
    "        # your code goes here\n",
    "        super(WSDModel_approach2, self).__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_dim, h_dim)\n",
    "        self.rnn = nn.LSTM(h_dim, h_dim, batch_first=True)\n",
    "        self.classifier = nn.Linear(h_dim, num_senses) # TODO total senses or a word's senses?\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, batch):\n",
    "        # Select columns\n",
    "        position, lemma, context = batch.position, batch.lemma, batch.context\n",
    "        \n",
    "        #Embed the inputs => # B,SeqLen,HD\n",
    "        position, lemma, context = self.embeddings(position), self.embeddings(lemma), self.embeddings(context)\n",
    "        \n",
    "        #Merge the embeddding tensors by concat & multiplying\n",
    "        multiplication = position*lemma*context # B,S,HD\n",
    "        fullcontext = torch.cat([position, lemma, context, multiplication], dim=1) # B,S*4,HD\n",
    "\n",
    "        #Put the embeddings through RNN\n",
    "        rep, (_, _) = self.rnn(fullcontext)\n",
    "        rep = torch.sum(rep, dim=1) # B,CtxLen,HD => B,HD\n",
    "        rep = self.dropout(rep)\n",
    "        \n",
    "        # Predict the class from RNN output\n",
    "        predictions = self.classifier(rep)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing the model\n",
    "\n",
    "Now we are ready to train and test our model. What we need now is a loss function, an optimizer, and our data. \n",
    "\n",
    "- First, create the loss function and the optimizer.\n",
    "- Next, we iterate over the number of epochs (i.e. how many times we let the model see our data). \n",
    "- For each epoch, iterate over the dataset (``train_iter``) to obtain batches. Use the batch as input to the model, and let the model output scores for the different word senses.\n",
    "- For each model output, calculate the loss (and print the loss) on the output and update the model parameters.\n",
    "- Reset the gradients and repeat.\n",
    "- After all epochs are done, test your trained model on the test set (``test_iter``) and calculate the total and per-word-form accuracy of your model.\n",
    "\n",
    "Implement the training and testing of the model **[4 marks]**\n",
    "\n",
    "**Suggestion for efficiency:** *when developing your model, try training and testing the model on one or two batches (for each epoch) of data to make sure everything works! It's very annoying if you train for N epochs to find out that something went wrong when testing the model, or to find that something goes wrong when moving from epoch 0 to epoch 1.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split raw data => Load train & test sets\n",
    "data_split('wsd-data/wsd_data.txt')\n",
    "train_iter, test_iter, vocab, labels = dataloader( 'wsd-data/', batch_size=batch_size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg total loss 1: 1.746262686383584  Avg total loss 2: 2.74005332560442266\r"
     ]
    }
   ],
   "source": [
    "#Params\n",
    "vocab_dim,num_labels = len(vocab),len(labels)  # V=70521, L=224\n",
    "h_dim = 256  # Or use in_dim=32 during dev...?\n",
    "\n",
    "wsd1_model = WSDModel_approach1(vocab_dim, num_labels, h_dim)\n",
    "wsd1_model.to(device)\n",
    "wsd2_model = WSDModel_approach2(vocab_dim, num_labels, h_dim)\n",
    "wsd2_model.to(device)\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer1 = torch.optim.Adam(wsd1_model.parameters(), lr=learning_rate)\n",
    "optimizer2 = torch.optim.Adam(wsd2_model.parameters(), lr=learning_rate)\n",
    "\n",
    "#Training 1st model\n",
    "from statistics import mean\n",
    "total_loss1, total_loss2 = [],[]\n",
    "for _ in range(epochs):\n",
    "    \n",
    "    total_loss1.clear()\n",
    "    total_loss2.clear()\n",
    "    \n",
    "    for i, batch in enumerate(train_iter):\n",
    "        \n",
    "        label = batch.sense  # gold labels of batch\n",
    "        output1 = wsd1_model(batch)\n",
    "        output2 = wsd2_model(batch)\n",
    "        \n",
    "#         print(output.view(-1, num_labels).shape) # 8,1,224\n",
    "#         print(label.shape)\n",
    "#         break\n",
    "        \n",
    "        loss1 = loss_function(output1.view(-1, num_labels), label.view(-1)) # modelout:(B,num_labels), target:(B,1)\n",
    "        total_loss1 += [loss1.item()]\n",
    "        \n",
    "        loss2 = loss_function(output2.view(-1, num_labels), label.view(-1)) # modelout:(B,num_labels), target:(B,1)\n",
    "        total_loss2 += [loss2.item()]\n",
    "        \n",
    "        print(f'Avg total loss 1: {mean(total_loss1)}  Avg total loss 2: {mean(total_loss2)}', end='\\r')\n",
    "        \n",
    "        # compute gradients; # update parameters; # reset gradients\n",
    "        loss1.backward();     optimizer1.step();    optimizer1.zero_grad()\n",
    "        loss2.backward();     optimizer2.step();    optimizer2.zero_grad()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg test loss 1:  1.5284331385828869   Avg test loss 2:  1.4045850108651554\r"
     ]
    }
   ],
   "source": [
    "# test model after all epochs are completed\n",
    "# Test WSD1&2 with the test_iter\n",
    "test_loss1,test_loss2 = [],[]\n",
    "wsd1_model.eval()\n",
    "wsd2_model.eval()\n",
    "\n",
    "# iterate over the test data and compute the class probabilities, same\n",
    "# procedure as before, but now we don't backpropagate\n",
    "for i, batch in enumerate(test_iter):\n",
    "    \n",
    "    label = batch.sense  # gold labels of batch\n",
    "\n",
    "    with torch.no_grad(): # dont collect gradients when testing\n",
    "        # Given batch => Predict label\n",
    "        output1, output2 = wsd1_model(batch), wsd2_model(batch)\n",
    "    batch_loss1 = loss_function(output1.view(-1,num_labels), label.view(-1))\n",
    "    batch_loss2 = loss_function(output2.view(-1,num_labels), label.view(-1))\n",
    "    test_loss1 += [batch_loss1.item()]\n",
    "    test_loss2 += [batch_loss2.item()]\n",
    "\n",
    "    print('Avg test loss 1: ', mean(test_loss1), '  Avg test loss 2: ', mean(test_loss2), end='\\r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WSDModel_approach2(\n",
       "  (embeddings): Embedding(70219, 256)\n",
       "  (rnn): LSTM(256, 256, batch_first=True)\n",
       "  (classifier): Linear(in_features=256, out_features=224, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save:\n",
    "# torch.save(wsd1_model.state_dict(), 'wsd1_model.pt')\n",
    "# torch.save(wsd2_model.state_dict(), 'wsd2_model.pt')\n",
    "\n",
    "# Load:\n",
    "_, test_iter, vocab, labels = dataloader( 'wsd-data/', batch_size=128 )\n",
    "del _\n",
    "vocab_dim,num_labels = len(vocab),len(labels)  # V=70521, L=224\n",
    "h_dim = 256\n",
    "\n",
    "wsd1_model = WSDModel_approach1(vocab_dim, num_labels, h_dim)\n",
    "wsd1_model.load_state_dict(torch.load('wsd1_model.pt'), )\n",
    "wsd1_model.eval()\n",
    "\n",
    "wsd2_model = WSDModel_approach2(vocab_dim, num_labels, h_dim)\n",
    "wsd2_model.load_state_dict(torch.load('wsd2_model.pt'), )\n",
    "wsd2_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Running a transformer for WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section of the lab you'll try out the transformer, specifically the BERT model. For this we'll use the huggingface library (https://huggingface.co/).\n",
    "\n",
    "You can find the documentation for the BERT model here (https://huggingface.co/transformers/model_doc/bert.html) and a general usage guide here (https://huggingface.co/transformers/quickstart.html).\n",
    "\n",
    "What we're going to do is *fine-tune* the BERT model, i.e. update the weights of a pre-trained model. That is, we have a model that is trained on language modeling, but now we apply it to word sense disambiguation with the word representations it learnt from language modeling.\n",
    "\n",
    "We'll use the same data splits for training and testing as before, but this time you'll not use a torchtext dataloader. Rather now you create an iterator that collects N sentences (where N is the batch size) then use the BertTokenizer to transform the sentence into integers. For your dataloader, remember to:\n",
    "* Shuffle the data in each batch\n",
    "* Make sure you get a new iterator for each *epoch*\n",
    "* Create a vocabulary of *sense-labels* so you can calculate accuracy \n",
    "\n",
    "We then pass this batch into the BERT model and train as before. The BERT model will encode the sentence, then we send this encoded sentence into a prediction layer (you can either the the sentence-representation from bert, or the ambiguous word) like before and collect sense predictions.\n",
    "\n",
    "About the hyperparameters and training:\n",
    "* For BERT, usually a lower learning rate works best, between 0.0001-0.000001.\n",
    "* BERT takes alot of resources, running it on CPU will take ages, utilize the GPUs :)\n",
    "* Since BERT takes alot of resources, use a small batch size (4-8)\n",
    "* Computing the BERT representation, make sure you pass the mask\n",
    "\n",
    "**[10 marks]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn each batch (batchsize of lines) into an obj, where each column is an attribute\n",
    "\n",
    "def bert_tensor(seq, max_length=16):\n",
    "    tensor = tokenizer.encode(seq, return_tensors='pt', max_length=max_length, pad_to_max_length=True)\n",
    "    return tensor\n",
    "\n",
    "def bert_attn_mask(seq, max_length=16):\n",
    "    tensor = tokenizer.encode_plus(seq, return_tensors='pt', max_length=max_length, pad_to_max_length=True,\n",
    "                                   return_attention_mask=True)\n",
    "    return tensor['attention_mask']\n",
    "\n",
    "def bert_tensor_no_pad(seq):\n",
    "    tensor = tokenizer.encode(seq, return_tensors='pt')\n",
    "    return tensor\n",
    "    \n",
    "class Batch():\n",
    "    def __init__(self, batchlines, dictionary):\n",
    "        self.sense = torch.tensor( [ [dictionary[l[0]]] for l in batchlines] ).to(device)\n",
    "        self.context = torch.stack( [bert_tensor(l[3], 384) for l in batchlines], dim=1 )[0].to(device)\n",
    "        self.context_attn_mask = torch.stack( [bert_attn_mask(l[3], 384) for l in batchlines], dim=1 )[0].to(device)\n",
    "        \n",
    "from random import shuffle\n",
    "def dataloader_for_bert(path_to_file, batch_size):\n",
    "    '''Shuffles lines of file, then yield a batch'''\n",
    "    sensevocab = [] \n",
    "    \n",
    "    # Iterate through the rows\n",
    "    with open(path_to_file, encoding='utf8') as f:\n",
    "        lines = []  # 76049 lines \n",
    "        for l in f:\n",
    "            columns = sense, lemma, position, context = l.rstrip('\\n').split('\\t')\n",
    "            \n",
    "            if sense not in sensevocab:\n",
    "                sensevocab.append(sense)\n",
    "            \n",
    "            lines.append(columns)\n",
    "    \n",
    "    #Convert list of senses to dictionary of indexed senses\n",
    "    sensevocab_itos = dict( enumerate(sensevocab) )\n",
    "    sensevocab_stoi = {x:i for i,x in sensevocab_itos.items()}\n",
    "    \n",
    "    #Shuffle rows and make generator\n",
    "    shuffle(lines)\n",
    "    n = max(1, batch_size)\n",
    "    generator = (Batch(lines[i:i+n], sensevocab_stoi) for i in range(0, len(lines), n))\n",
    "        \n",
    "    return generator, sensevocab_itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator, sensevocab = dataloader_for_bert('wsd-data/wsd_data-train.csv',8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[156],\n",
      "        [ 99],\n",
      "        [135],\n",
      "        [ 84],\n",
      "        [ 96],\n",
      "        [102],\n",
      "        [ 17],\n",
      "        [161]])\n",
      "['position%1:15:00::', 'active%5:00:00:operational:00', 'force%1:07:01::', 'lead%2:38:00::', 'life%1:26:01::', 'case%1:26:00::', 'case%1:11:00::', 'national%3:00:00::']\n"
     ]
    }
   ],
   "source": [
    "for i, bat in enumerate(generator):\n",
    "#     ctx = bat.context\n",
    "#     ctx_attn_mask = bat.context_attn_mask\n",
    "# #     print( tokenizer.convert_ids_to_tokens(ctx[0]) ) # tensor=>list of strings\n",
    "#     print( tokenizer.decode(ctx[0]) ) # tensor=> sequence string\n",
    "#     print(ctx_attn_mask[0]) # [1,1,1...0,0,0] where 1 means other tokens and 0 means [PAD]\n",
    "    print(bat.sense)\n",
    "    print( [ sensevocab[int(i)] for i in bat.sense.view(-1)] )\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel\n",
    "class BERT_WSD(nn.Module):\n",
    "    def __init__(self, in_dim, h_dim, out_dim):\n",
    "        super(BERT_WSD, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.classifier =  nn.Sequential( nn.Linear(in_dim, h_dim), nn.ReLU(), nn.Linear(h_dim, out_dim) )\n",
    "        \n",
    "    def forward(self, bat):\n",
    "        ctx, ctx_attn, sense = bat.context, bat.context_attn_mask, bat.sense\n",
    "        input_ids, attnmask, label = ctx.to(device), ctx_attn.to(device), sense.to(device)\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attnmask) #([B,Seq,768], [B,768])\n",
    "        first_hidden_state_cls = outputs[0][:, 0, :] # B, 768 => [CLS] token of last layer\n",
    "        predictions = self.classifier(first_hidden_state_cls)  # B, 222\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "device=torch.device('cuda:3')\n",
    "\n",
    "# _, sensevocab = dataloader_for_bert('wsd-data/wsd_data-train.csv', batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average total loss: 2.7584107885259157\n",
      "Average total loss: 1.1459777694163182\n",
      "Average total loss: 0.7890831329478987\n"
     ]
    }
   ],
   "source": [
    "bert_lr = 2e-5 # -4~-6\n",
    "\n",
    "from transformers import AdamW\n",
    "\n",
    "bert_wsd_model = BERT_WSD(768,50, len(sensevocab))\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = AdamW(bert_wsd_model.parameters(), lr=bert_lr, eps = 1e-8)\n",
    "bert_wsd_model.to(device)\n",
    "\n",
    "\n",
    "# train model\n",
    "from statistics import mean\n",
    "train_loss = []\n",
    "for _ in range(epochs):\n",
    "    \n",
    "    #The generator is exhausted at the end of an epoch so needs to be remade\n",
    "    train_generator, _ = dataloader_for_bert('wsd-data/wsd_data-train.csv', batch_size)\n",
    "\n",
    "    train_loss.clear()\n",
    "    bert_wsd_model.train()\n",
    "    \n",
    "    for i,bat in enumerate(train_generator):\n",
    "        \n",
    "        label = bat.sense.to(device)\n",
    "        output = bert_wsd_model(bat)\n",
    "#         print(label.shape) #B, 1\n",
    "#         print(output.shape) # B,222\n",
    "#         break\n",
    "        \n",
    "        loss = loss_function( output, label.view(-1) ) \n",
    "        train_loss.append( loss.item() )\n",
    "\n",
    "        print(f'Average total loss: {mean(train_loss)}', end='\\r')\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(bert_wsd_model.parameters(), 1.0)\n",
    "        \n",
    "        # compute gradients; # update parameters; # reset gradients\n",
    "        loss.backward();     optimizer.step();    optimizer.zero_grad()\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_WSD(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=50, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=50, out_features=222, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save:\n",
    "# torch.save(bert_wsd_model.state_dict(), 'bert_model.pt')\n",
    "\n",
    "# Load:\n",
    "_, sensevocab = dataloader_for_bert('wsd-data/wsd_data-train.csv', 128)\n",
    "bert_wsd_model = BERT_WSD(768,50, len(sensevocab))\n",
    "bert_wsd_model.load_state_dict(torch.load('bert_model.pt'), )\n",
    "bert_wsd_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LSTM 1 accuracy</th>\n",
       "      <th>LSTM 2 accuracy</th>\n",
       "      <th>BERT accuracy</th>\n",
       "      <th>MCS baseline</th>\n",
       "      <th>Nr of senses</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>keep</th>\n",
       "      <td>0.569ðŸ™‚</td>\n",
       "      <td>0.715ðŸ™‚</td>\n",
       "      <td>0.91ðŸ™‚</td>\n",
       "      <td>0.392</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hold</th>\n",
       "      <td>0.199ðŸ™‚</td>\n",
       "      <td>0.561ðŸ™‚</td>\n",
       "      <td>0.854ðŸ™‚</td>\n",
       "      <td>0.152</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>see</th>\n",
       "      <td>0.612ðŸ¤¢</td>\n",
       "      <td>0.732ðŸ™‚</td>\n",
       "      <td>0.915ðŸ™‚</td>\n",
       "      <td>0.628</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line</th>\n",
       "      <td>0.862ðŸ™‚</td>\n",
       "      <td>0.934ðŸ™‚</td>\n",
       "      <td>0.987ðŸ™‚</td>\n",
       "      <td>0.851</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>follow</th>\n",
       "      <td>0.367ðŸ™‚</td>\n",
       "      <td>0.559ðŸ™‚</td>\n",
       "      <td>0.798ðŸ™‚</td>\n",
       "      <td>0.146</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>build</th>\n",
       "      <td>0.23ðŸ™‚</td>\n",
       "      <td>0.321ðŸ™‚</td>\n",
       "      <td>0.611ðŸ™‚</td>\n",
       "      <td>0.212</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>find</th>\n",
       "      <td>0.375ðŸ™‚</td>\n",
       "      <td>0.52ðŸ™‚</td>\n",
       "      <td>0.866ðŸ™‚</td>\n",
       "      <td>0.232</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serve</th>\n",
       "      <td>0.213ðŸ™‚</td>\n",
       "      <td>0.549ðŸ™‚</td>\n",
       "      <td>0.816ðŸ™‚</td>\n",
       "      <td>0.155</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>life</th>\n",
       "      <td>0.213ðŸ¤¢</td>\n",
       "      <td>0.65ðŸ™‚</td>\n",
       "      <td>0.915ðŸ™‚</td>\n",
       "      <td>0.225</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead</th>\n",
       "      <td>0.212ðŸ™‚</td>\n",
       "      <td>0.412ðŸ™‚</td>\n",
       "      <td>0.781ðŸ™‚</td>\n",
       "      <td>0.180</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>point</th>\n",
       "      <td>0.547ðŸ™‚</td>\n",
       "      <td>0.66ðŸ™‚</td>\n",
       "      <td>0.918ðŸ™‚</td>\n",
       "      <td>0.355</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>case</th>\n",
       "      <td>0.351ðŸ™‚</td>\n",
       "      <td>0.49ðŸ™‚</td>\n",
       "      <td>0.791ðŸ™‚</td>\n",
       "      <td>0.204</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>force</th>\n",
       "      <td>0.284ðŸ™‚</td>\n",
       "      <td>0.756ðŸ™‚</td>\n",
       "      <td>0.901ðŸ™‚</td>\n",
       "      <td>0.163</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>regular</th>\n",
       "      <td>0.204ðŸ¤¢</td>\n",
       "      <td>0.556ðŸ™‚</td>\n",
       "      <td>0.744ðŸ™‚</td>\n",
       "      <td>0.217</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bring</th>\n",
       "      <td>0.269ðŸ™‚</td>\n",
       "      <td>0.475ðŸ™‚</td>\n",
       "      <td>0.764ðŸ™‚</td>\n",
       "      <td>0.212</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>security</th>\n",
       "      <td>0.406ðŸ™‚</td>\n",
       "      <td>0.745ðŸ™‚</td>\n",
       "      <td>0.917ðŸ™‚</td>\n",
       "      <td>0.203</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>extend</th>\n",
       "      <td>0.361ðŸ™‚</td>\n",
       "      <td>0.571ðŸ™‚</td>\n",
       "      <td>0.76ðŸ™‚</td>\n",
       "      <td>0.180</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>place</th>\n",
       "      <td>0.367ðŸ™‚</td>\n",
       "      <td>0.664ðŸ™‚</td>\n",
       "      <td>0.871ðŸ™‚</td>\n",
       "      <td>0.243</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>position</th>\n",
       "      <td>0.323ðŸ™‚</td>\n",
       "      <td>0.554ðŸ™‚</td>\n",
       "      <td>0.9ðŸ™‚</td>\n",
       "      <td>0.202</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>0.211ðŸ™‚</td>\n",
       "      <td>0.575ðŸ™‚</td>\n",
       "      <td>0.804ðŸ™‚</td>\n",
       "      <td>0.205</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physical</th>\n",
       "      <td>0.217ðŸ¤¢</td>\n",
       "      <td>0.589ðŸ™‚</td>\n",
       "      <td>0.868ðŸ™‚</td>\n",
       "      <td>0.236</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>critical</th>\n",
       "      <td>0.289ðŸ™‚</td>\n",
       "      <td>0.633ðŸ™‚</td>\n",
       "      <td>0.94ðŸ™‚</td>\n",
       "      <td>0.274</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>active</th>\n",
       "      <td>0.282ðŸ¤¢</td>\n",
       "      <td>0.672ðŸ™‚</td>\n",
       "      <td>0.923ðŸ™‚</td>\n",
       "      <td>0.320</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>professional</th>\n",
       "      <td>0.193ðŸ¤¢</td>\n",
       "      <td>0.724ðŸ™‚</td>\n",
       "      <td>0.865ðŸ™‚</td>\n",
       "      <td>0.218</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>order</th>\n",
       "      <td>0.21ðŸ¤¢</td>\n",
       "      <td>0.677ðŸ™‚</td>\n",
       "      <td>0.943ðŸ™‚</td>\n",
       "      <td>0.220</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>positive</th>\n",
       "      <td>0.37ðŸ™‚</td>\n",
       "      <td>0.724ðŸ™‚</td>\n",
       "      <td>0.904ðŸ™‚</td>\n",
       "      <td>0.354</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <td>0.313ðŸ™‚</td>\n",
       "      <td>0.571ðŸ™‚</td>\n",
       "      <td>0.864ðŸ™‚</td>\n",
       "      <td>0.279</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>common</th>\n",
       "      <td>0.267ðŸ™‚</td>\n",
       "      <td>0.517ðŸ™‚</td>\n",
       "      <td>0.824ðŸ™‚</td>\n",
       "      <td>0.251</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bad</th>\n",
       "      <td>0.641ðŸ™‚</td>\n",
       "      <td>0.752ðŸ™‚</td>\n",
       "      <td>0.926ðŸ™‚</td>\n",
       "      <td>0.607</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>major</th>\n",
       "      <td>0.283ðŸ¤¢</td>\n",
       "      <td>0.457ðŸ™‚</td>\n",
       "      <td>0.82ðŸ™‚</td>\n",
       "      <td>0.303</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             LSTM 1 accuracy LSTM 2 accuracy BERT accuracy  MCS baseline  \\\n",
       "keep                  0.569ðŸ™‚          0.715ðŸ™‚         0.91ðŸ™‚         0.392   \n",
       "hold                  0.199ðŸ™‚          0.561ðŸ™‚        0.854ðŸ™‚         0.152   \n",
       "see                   0.612ðŸ¤¢          0.732ðŸ™‚        0.915ðŸ™‚         0.628   \n",
       "line                  0.862ðŸ™‚          0.934ðŸ™‚        0.987ðŸ™‚         0.851   \n",
       "follow                0.367ðŸ™‚          0.559ðŸ™‚        0.798ðŸ™‚         0.146   \n",
       "build                  0.23ðŸ™‚          0.321ðŸ™‚        0.611ðŸ™‚         0.212   \n",
       "find                  0.375ðŸ™‚           0.52ðŸ™‚        0.866ðŸ™‚         0.232   \n",
       "serve                 0.213ðŸ™‚          0.549ðŸ™‚        0.816ðŸ™‚         0.155   \n",
       "life                  0.213ðŸ¤¢           0.65ðŸ™‚        0.915ðŸ™‚         0.225   \n",
       "lead                  0.212ðŸ™‚          0.412ðŸ™‚        0.781ðŸ™‚         0.180   \n",
       "point                 0.547ðŸ™‚           0.66ðŸ™‚        0.918ðŸ™‚         0.355   \n",
       "case                  0.351ðŸ™‚           0.49ðŸ™‚        0.791ðŸ™‚         0.204   \n",
       "force                 0.284ðŸ™‚          0.756ðŸ™‚        0.901ðŸ™‚         0.163   \n",
       "regular               0.204ðŸ¤¢          0.556ðŸ™‚        0.744ðŸ™‚         0.217   \n",
       "bring                 0.269ðŸ™‚          0.475ðŸ™‚        0.764ðŸ™‚         0.212   \n",
       "security              0.406ðŸ™‚          0.745ðŸ™‚        0.917ðŸ™‚         0.203   \n",
       "extend                0.361ðŸ™‚          0.571ðŸ™‚         0.76ðŸ™‚         0.180   \n",
       "place                 0.367ðŸ™‚          0.664ðŸ™‚        0.871ðŸ™‚         0.243   \n",
       "position              0.323ðŸ™‚          0.554ðŸ™‚          0.9ðŸ™‚         0.202   \n",
       "national              0.211ðŸ™‚          0.575ðŸ™‚        0.804ðŸ™‚         0.205   \n",
       "physical              0.217ðŸ¤¢          0.589ðŸ™‚        0.868ðŸ™‚         0.236   \n",
       "critical              0.289ðŸ™‚          0.633ðŸ™‚         0.94ðŸ™‚         0.274   \n",
       "active                0.282ðŸ¤¢          0.672ðŸ™‚        0.923ðŸ™‚         0.320   \n",
       "professional          0.193ðŸ¤¢          0.724ðŸ™‚        0.865ðŸ™‚         0.218   \n",
       "order                  0.21ðŸ¤¢          0.677ðŸ™‚        0.943ðŸ™‚         0.220   \n",
       "positive               0.37ðŸ™‚          0.724ðŸ™‚        0.904ðŸ™‚         0.354   \n",
       "time                  0.313ðŸ™‚          0.571ðŸ™‚        0.864ðŸ™‚         0.279   \n",
       "common                0.267ðŸ™‚          0.517ðŸ™‚        0.824ðŸ™‚         0.251   \n",
       "bad                   0.641ðŸ™‚          0.752ðŸ™‚        0.926ðŸ™‚         0.607   \n",
       "major                 0.283ðŸ¤¢          0.457ðŸ™‚         0.82ðŸ™‚         0.303   \n",
       "\n",
       "              Nr of senses  \n",
       "keep                    11  \n",
       "hold                    11  \n",
       "see                     11  \n",
       "line                    11  \n",
       "follow                  11  \n",
       "build                   10  \n",
       "find                    10  \n",
       "serve                    9  \n",
       "life                     9  \n",
       "lead                     8  \n",
       "point                    8  \n",
       "case                     8  \n",
       "force                    8  \n",
       "regular                  8  \n",
       "bring                    8  \n",
       "security                 7  \n",
       "extend                   7  \n",
       "place                    7  \n",
       "position                 6  \n",
       "national                 6  \n",
       "physical                 6  \n",
       "critical                 5  \n",
       "active                   5  \n",
       "professional             5  \n",
       "order                    5  \n",
       "positive                 5  \n",
       "time                     5  \n",
       "common                   4  \n",
       "bad                      4  \n",
       "major                    4  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EVALUATION OF MODELS (compare to each other and the MCS baselines)\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def eval_models():\n",
    "    # Run both models on test data and count the correct vs total predictions of each lemma\n",
    "    dict1, dict2, dict3 = {},{},{}\n",
    "    for index,bat in enumerate(test_iter):\n",
    "        label = bat.sense\n",
    "        \n",
    "        with torch.no_grad(): # dont collect gradients when testing\n",
    "            # B,1,L\n",
    "            output1, output2 = wsd1_model(bat), wsd2_model(bat)\n",
    "\n",
    "        #Iterate through the predictions & gold labels of a batch\n",
    "        for output,dictionary in [(output1,dict1), (output2,dict2)]:\n",
    "            for i in range(len(bat)):\n",
    "                idx_of_max_val = torch.argmax(output[i].view(-1))\n",
    "                prediction = labels.itos[idx_of_max_val]\n",
    "\n",
    "                gold = labels.itos[label[i]]\n",
    "                goldlemma = gold[:gold.index('%')]\n",
    "\n",
    "                if goldlemma not in dictionary:\n",
    "                    dictionary[goldlemma]=[0,0] # correct_predictions, total_count of a word lemma\n",
    "                w = dictionary[goldlemma]\n",
    "                w[0]+=int(gold==prediction)\n",
    "                w[1]+=1\n",
    "                \n",
    "    for index,bat in enumerate(test_generator):\n",
    "        label = bat.sense\n",
    "        \n",
    "        with torch.no_grad(): # dont collect gradients when testing\n",
    "            output = bert_wsd_model(bat)\n",
    "\n",
    "        #Iterate through the predictions & gold labels of a batch\n",
    "        for i in range(bat.sense.shape[0]):\n",
    "            idx_of_max_val = torch.argmax(output[i])\n",
    "            prediction = sensevocab[ int(idx_of_max_val) ]\n",
    "\n",
    "            gold = sensevocab[ int(label[i]) ]\n",
    "            goldlemma = gold[:gold.index('%')]\n",
    "\n",
    "            if goldlemma not in dict3:\n",
    "                dict3[goldlemma]=[0,0] # correct_predictions, total_count of a word lemma\n",
    "            w = dict3[goldlemma]\n",
    "            w[0]+=int(gold==prediction)\n",
    "            w[1]+=1\n",
    "        \n",
    "\n",
    "    # Compute the lemmas' respective accuracies and compare with MCS baselines\n",
    "    baselinedict = mcs_baseline('wsd-data/wsd_data.txt')  \n",
    "    stats = {} # The per-word-form accuracy\n",
    "    for lemma in baselinedict:\n",
    "        accu = lambda duos : [duo[0]/duo[1] for duo in duos]\n",
    "        accuracy1, accuracy2, accuracy3 = accu( [dict1[lemma], dict2[lemma], dict3[lemma]] )\n",
    "\n",
    "        mcsdict = baselinedict[lemma]\n",
    "        mcs = mcsdict['mcs']\n",
    "        numsenses = mcsdict['senses']\n",
    "        res = lambda accuracy : 'ðŸ™‚' if accuracy>mcs else 'ðŸ¤¢'  # Marks whether it's better or worse than MCS\n",
    "\n",
    "        stats[lemma] = {\n",
    "            'LSTM 1 accuracy':f'{round(accuracy1,3)}{res(accuracy1)}',\n",
    "            'LSTM 2 accuracy':f'{round(accuracy2,3)}{res(accuracy2)}',\n",
    "            'BERT accuracy':f'{round(accuracy3,3)}{res(accuracy3)}',\n",
    "            'MCS baseline':round(mcs,3), \n",
    "            'Nr of senses':numsenses\n",
    "        }\n",
    "\n",
    "    df = pd.DataFrame.from_dict(stats, orient='index').sort_values(by='Nr of senses', ascending=False)\n",
    "    return df\n",
    "\n",
    "\n",
    "wsd1_model.to(device); wsd2_model.to(device); bert_wsd_model.to(device)\n",
    "_, test_iter, vocab, labels = dataloader( 'wsd-data/', batch_size=128 )\n",
    "test_generator, sensevocab = dataloader_for_bert('wsd-data/wsd_data-test.csv', 128)\n",
    "\n",
    "eval_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain the difference between the first and second approach. What kind of representations are the different approaches using to predict word-senses? **[4 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "\n",
    "**LSTM 1:**\n",
    "Originally we chose 'column 3' as instructed but it doesn't make sense to give the integer and predict the sense. So we used the integer to select the i-th token id in the context, which means the models only gets the word (could be its variant forms instead of the lemma) and tries to predict the sense. \n",
    "\n",
    "Eg, Given position='4' and context=`[please stay in the lines]`, the model gets the vocab id for `'lines'` and tries to predict a sense out of all the word senses, including out of those for `'line'`.\n",
    "\n",
    "**LSTM 2:**\n",
    "The second model is given the full context, ie, a combined tensor of `[position, lemma, context, position x lemma x context]`. The models performs better than the MCS for each lemma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate your model with per-word-form *accuracy* and comment on the results you get, how does the model perform in comparison to the baseline, and how do the models compare to each other? \n",
    "\n",
    "Expand on the evaluation by sorting the word-forms by the number of senses they have. Are word-forms with fewer senses easier to predict? Give a short explanation of the results you get based on the number of senses per word.\n",
    "\n",
    "**[6 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "\n",
    "Model 2 performs better than model 1 and the MCS. \n",
    "In the cases where model 1 performs worse than the MCS, the accuracies are mostly just below the MCS, suggesting that it outputs the most common sense of the word.\n",
    "\n",
    "Regarding the number of word sense, model 1 has instances where it performs worse the MCS for both words with fewer and more senses, so we conclude that the number of word senses doesn't necessarily play a role in the accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does the LSTMs perform in comparison to BERT? What's the difference between representations obtained by the LSTMs and BERT? **[2 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "\n",
    "Both the LSTM2 model and BERT performed well, but BERT has 80~90 percent accuracy for most words. Note that we only gave the context sentence as input, without combining the position or the lemma tensors (which could've been done and possibly helped with the performance) because of the efficiency considerations and the complexity of having to also deal with attention masks).\n",
    "\n",
    "**Diffrences in representations**\n",
    "\n",
    "When tokenizing the data for LSTM, we only separate and lowercase the words and build an indexed vocabulary, which would ineviably contain various forms of the same word.\n",
    "\n",
    "On the other hand, the data for BERT uses the prebuild tokenizer and BERT vocab, where the words are broken down into subwords in the BERT vocab. Thus different words in the input can be represented as lemma+##suffix instead of different vocab entries as in the case of LSTM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What could we do to improve our LSTM word sense disambiguation models and our BERT model? **[4 marks]**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ans:**\n",
    "\n",
    "Based on the inputs we gave to the LSTM models, the informations given to the model training and the way the representation are combined greatly affects the performance. Apart from formatting the input, we can also implement deeper layers in the model to extract further information from the more general data from previous layers. \n",
    "\n",
    "As for BERT fine tuning, it may be beneficial to utilize the pretrained model and its vocabulary. In our model, for example, we represented the word senses in a separate vocab rather using the BERT tokenizer, but it may be a good idea to let context and sense share the same BERT vocab, since it can break words down to smaller subwords, so that the model can learn a better relationship between the sense and the context. Eg, with 'keep'+'##s' in the context, it should predict a sense that starts with 'keep'+'%'. Another benefit of tokenizing to the BERT vocab is that the token ids will be consistent across different datasets (instead of built from our own data), which will facillitate evaluating and comparing a variety of datasets and models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Readings:\n",
    "\n",
    "[1] KÃ¥gebÃ¤ck, M., & Salomonsson, H. (2016). Word Sense Disambiguation using a Bidirectional LSTM. arXiv preprint arXiv:1606.03568.\n",
    "\n",
    "[2] https://cl.lingfil.uu.se/~nivre/master/NLP-LexSem.pdf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
